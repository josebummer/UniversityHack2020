{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from scipy.special import softmax\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leer datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../src/data/train.txt',sep='|',index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../src/data/test.txt',sep='|',index_col='ID')\n",
    "df_test['CLASE'] = \"NONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.concat([df,df_test],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesar NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder().fit(df.CLASE)\n",
    "\n",
    "df_final = df_join.copy()\n",
    "df_final.MAXBUILDINGFLOOR = df_final.MAXBUILDINGFLOOR.fillna(1)\n",
    "df_final.CADASTRALQUALITYID = df_final.CADASTRALQUALITYID.fillna('7')\n",
    "df_final.CADASTRALQUALITYID = df_final.CADASTRALQUALITYID.map({'9': '0','8': '1',\n",
    "                                                                 '7': '2',\n",
    "                                                                 '6': '3',\n",
    "                                                                 '5': '4',\n",
    "                                                                 '4': '5',\n",
    "                                                                 '3': '6',\n",
    "                                                                 '2': '7',\n",
    "                                                                 '1': '8',\n",
    "                                                                 'C': '9',\n",
    "                                                                 'B': '10',\n",
    "                                                                 'A': '11', }).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Transform RGBN to prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transform RGBN to prob\n",
    "#\n",
    "\n",
    "x = df_join[[x for x in df_join.columns if \"Q_\" in x]]\n",
    "y = df_join.CLASE\n",
    "clase = df.CLASE\n",
    "\n",
    "x_uniq = x.drop_duplicates().values\n",
    "x = x.values\n",
    "probs = np.zeros((x_uniq.shape[0],le.classes_.size))\n",
    "for i in range(x_uniq.shape[0]):\n",
    "    d = dict(zip(*np.unique(y[(x == x_uniq[i]).all(1)],return_counts=True)))\n",
    "    v = np.array([d.get(x,0) for x in le.classes_])\n",
    "    v = v/v.sum()\n",
    "    probs[i] = v\n",
    "probs[np.isnan(probs)] = 0.\n",
    "\n",
    "# Replace single instances with most common\n",
    "single_inst = np.isin(probs.max(1),[0,1])\n",
    "default_label = probs[single_inst].sum(0).argmax()\n",
    "default_v = np.zeros(probs.shape[1])\n",
    "default_v[default_label] = 1\n",
    "probs[single_inst] = default_v\n",
    "\n",
    "# Generate x_prob\n",
    "x_prob = np.zeros((x.shape[0],le.classes_.size))\n",
    "for r,v in zip(x_uniq,probs):\n",
    "    x_prob[(r == x).all(1)] = v\n",
    "    \n",
    "rgbn_df = pd.DataFrame(\n",
    "    x_prob,\n",
    "    index=df_join.index,\n",
    "    columns=[f'RGBN_PROB_{c}' for c in le.classes_])\n",
    "\n",
    "df_final = pd.concat([df_final,rgbn_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "# yp = le.inverse_transform(x_prob.argmax(1)[:clase.size])\n",
    "\n",
    "for i,c in enumerate(le.classes_):\n",
    "    a,b,_ = roc_curve(df.CLASE == c,x_prob[:clase.size,i])\n",
    "    plt.plot(a,b)\n",
    "plt.gca().set_aspect(aspect='equal')\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.legend(le.classes_)\n",
    "# x_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar coordenadas reales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "df_xy = df_final[['X','Y','CLASE']]\n",
    "\n",
    "\n",
    "xy = StandardScaler().fit_transform(df_xy[['X','Y']])\n",
    "df_xy.loc[:,['X','Y']] = xy\n",
    "\n",
    "# clase = LabelEncoder().fit_transform(df_join.CLASE).ravel()\n",
    "\n",
    "l= np.array([0.9081377,0.5703538,40.455716,-3.627461,0.9281298,0.5705203,40.455762,-3.62622,0.9360858,0.5848481,40.456461,-3.625699,0.7416685,0.7010128,40.46215,-3.638498,0.7613676,0.9099505,40.472564,-3.637233,0.7924592,0.7564925,40.464968,-3.635146,0.2415585,0.07398904,40.430733,-3.670671,0.2475881,0.0706299,40.430648,-3.670359,0.2370961,0.003628214,40.42735,-3.670965,0.3055157,-0.987926,40.37801,-3.665981,0.3063767,-1.012424,40.376827,-3.665957,0.1932484,-0.9052158,40.382082,-3.673394,-0.2123642,0.1171437,40.432837,-3.700311,-0.237763,0.03549111,40.428676,-3.701912,-0.2260408,-0.008040646,40.426585,-3.701115,-2.222735,-0.7149885,40.390552,-3.830743,-2.452621,-0.6939522,40.391495,-3.845708,-2.524583,-0.6638325,40.392986,-3.850581,-3.078021,2.979496,40.573765,-3.888845,-3.125023,2.962788,40.572925,-3.891917,-3.158685,3.144402,40.581957,-3.894241,0.09576253,3.722043,40.612135,-3.682071,0.0699344,3.720931,40.61206,-3.683762,-0.02520764,3.612812,40.606622,-3.689842])\n",
    "pxs,pys,mys,mxs = l.reshape(-1,4).T\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lmx = LinearRegression()\n",
    "lmx.fit(np.array(pxs)[:,None],mxs)\n",
    "lmy = LinearRegression()\n",
    "lmy.fit(np.array(pys)[:,None],mys)\n",
    "\n",
    "df_xyt = df_xy.copy()\n",
    "df_xyt.X = lmx.predict(df_xy.X.to_numpy()[:,None])\n",
    "df_xyt.Y = lmy.predict(df_xy.Y.to_numpy()[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_mapbox(df_xyt, lat=\"Y\", lon=\"X\",color=\"CLASE\", zoom=10, height=800, width=1200)\n",
    "fig.update_traces(marker=dict(size=8),\n",
    "                  selector=dict(mode='markers'))\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geom transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "geom = df_join[[x for x in df_join.columns if \"GEOM\" in x]].copy()\n",
    "geom.iloc[:,1:] = np.log(geom.iloc[:,1:])\n",
    "geom = ss.fit_transform(geom)\n",
    "for d in (geom.T):\n",
    "    sns.distplot(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "knn = KNeighborsClassifier(4, n_jobs=-1, metric='manhattan', weights='distance')\n",
    "clase = df.CLASE\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "clase_pred = cross_val_predict(knn,geom[:clase.size],clase,method='predict_proba')\n",
    "\n",
    "for i,c in enumerate(le.classes_):\n",
    "    a,b,_ = roc_curve(df.CLASE == c,clase_pred[:,i])\n",
    "    plt.plot(a,b)\n",
    "plt.gca().set_aspect(aspect='equal')\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.legend(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1)\n",
    "for c in le.classes_:\n",
    "    sns.distplot(geom[df_join.CLASE == c,0],ax=ax)\n",
    "plt.legend(le.classes_)\n",
    "\n",
    "fig,ax=plt.subplots(1)\n",
    "for c in le.classes_:\n",
    "    sns.distplot(geom[df_join.CLASE == c,1],ax=ax)\n",
    "\n",
    "fig,ax=plt.subplots(1)\n",
    "for c in le.classes_:\n",
    "    sns.distplot(geom[df_join.CLASE == c,2],ax=ax)\n",
    "    \n",
    "fig,ax=plt.subplots(1)\n",
    "for c in le.classes_:\n",
    "    sns.distplot(geom[df_join.CLASE == c,3],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = df_join[[x for x in df_join.columns if \"GEOM\" in x]].copy()\n",
    "geom.iloc[:,1:] = np.log(geom.iloc[:,1:])\n",
    "geom = ss.fit_transform(geom)\n",
    "for d in (geom.T):\n",
    "    sns.distplot(d)\n",
    "    \n",
    "nlist = 100\n",
    "k = 4\n",
    "agg = np.mean\n",
    "\n",
    "res = []\n",
    "\n",
    "db_matrix = geom\n",
    "\n",
    "for c in le.classes_:\n",
    "    class_mask = df_join.CLASE == c\n",
    "#     print(class_mask.sum())\n",
    "    \n",
    "    mean_d = np.zeros((class_mask.size,k))\n",
    "    \n",
    "    db = db_matrix[class_mask].astype(np.float32)\n",
    "    rest = db_matrix[~class_mask].astype(np.float32)\n",
    "\n",
    "    # Train db           # add may be a bit slower as well\n",
    "    nn = NearestNeighbors(k+1,n_jobs=-1,metric='manhattan')\n",
    "    nn.fit(db)\n",
    "    \n",
    "    # Predict train\n",
    "    D,I = nn.kneighbors(db)\n",
    "    mean_d[class_mask] = (D[:,1:])\n",
    "    \n",
    "    # Predict rest\n",
    "    D, I = nn.kneighbors(rest)\n",
    "    mean_d[~class_mask] = (D[:,:-1])\n",
    "    \n",
    "    res.append(mean_d)\n",
    "res = np.array(res)\n",
    "res = agg(res,axis=2).T\n",
    "\n",
    "#\n",
    "# GEOM DIST DATAFRAME\n",
    "#\n",
    "geom_dist = pd.DataFrame(res,index=df_join.index,columns=[f'GEOM_DIST4_{c}' for c in le.classes_])\n",
    "df_final = pd.concat([df_final,geom_dist],axis=1)\n",
    "\n",
    "#\n",
    "# GEOM DIST SOFTMAX\n",
    "#\n",
    "res_log = np.log(res+3e-2)\n",
    "res_log -= res_log.min()\n",
    "res_log /= res_log.max()\n",
    "res_log = 1-res_log\n",
    "\n",
    "geom_nn4_prob = pd.DataFrame(softmax(res_log,axis=1),index=df_join.index,columns=[f'GEOM_PROB_{c}' for c in le.classes_])\n",
    "df_final = pd.concat([df_final,geom_nn4_prob],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from scipy.special import softmax\n",
    "\n",
    "for i,c in enumerate(le.classes_):\n",
    "    a,b,_ = roc_curve(df.CLASE == c,softmax(res_log,axis=1)[:clase.size,i])\n",
    "    plt.plot(a,b)\n",
    "plt.gca().set_aspect(aspect='equal')\n",
    "plt.ylabel('TPR')\n",
    "plt.xlabel('FPR')\n",
    "plt.legend(le.classes_)\n",
    "# x_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join[['X','Y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlist = 100\n",
    "k = 5\n",
    "agg = np.mean\n",
    "\n",
    "res = []\n",
    "\n",
    "db_matrix = np.ascontiguousarray(df_xyt[['X','Y']].values.astype(np.float32))\n",
    "# db_matrix = db_matrix-db_matrix.min(0)\n",
    "\n",
    "d = db_matrix.shape[1]                           # dimension\n",
    "nlist = 100\n",
    "\n",
    "global_quantizer = faiss.IndexFlatL2(d)  # the other index    \n",
    "global_index = faiss.IndexIVFFlat(global_quantizer, d, nlist)\n",
    "\n",
    "global_index.train(db_matrix)\n",
    "global_index.add(db_matrix)    \n",
    "\n",
    "D,I = global_index.search(db_matrix,k+1)\n",
    "res_global = D[:,1:]\n",
    "res_global[(res_global[:,:] == 0)] = 1e-15\n",
    "\n",
    "for c in le.classes_:\n",
    "    class_mask = df_join.CLASE == c\n",
    "    \n",
    "    mean_d = np.zeros((class_mask.size,k))\n",
    "    \n",
    "    db = db_matrix[class_mask]\n",
    "    rest = db_matrix[~class_mask]\n",
    "\n",
    "\n",
    "    # Train db\n",
    "    quantizer = faiss.IndexFlatL2(d)  # the other index    \n",
    "    index = faiss.IndexIVFFlat(quantizer, d, nlist)\n",
    "#     index = faiss.IndexFlatL2(d)\n",
    "    index.train(db)\n",
    "    index.add(db)                  # add may be a bit slower as well\n",
    "    \n",
    "    # Predict train\n",
    "    D, I = index.search(db, k+1)     # neighbors of the 5 last queries\n",
    "#     mean_d[class_mask] = agg(D[:,1:],axis=1)\n",
    "    mean_d[class_mask] = (D[:,1:])\n",
    "    \n",
    "    # Predict rest\n",
    "    D, I = index.search(rest, k)     # neighbors of the 5 last queries\n",
    "#     mean_d[~class_mask] = agg(D,axis=1)\n",
    "    mean_d[~class_mask] = (D)\n",
    "    \n",
    "    res.append(mean_d)\n",
    "res = np.array(res).transpose(1,0,2)\n",
    "res[res == 0] = 1e-15\n",
    "# res = agg(res,axis=2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_pond = (res/np.mean(res_global[:,None,:],axis=2,keepdims=True))\n",
    "res_pond = res_pond.reshape(-1,k*7)\n",
    "# res_pond = ((res_pond)-res_pond.mean())/res_pond.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_dens_dist = pd.DataFrame(res_pond,index=df_join.index,columns=[f'XY_DENS_{c}_{i}' for c in le.classes_ for i in range(k)])\n",
    "df_final = pd.concat([df_final,xy_dens_dist],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cols = ['CONTRUCTIONYEAR', 'MAXBUILDINGFLOOR', 'CADASTRALQUALITYID','AREA']\n",
    "rgbn_cols = [x for x in df_final.columns if \"RGBN_PROB_\" in x]\n",
    "geom_ori_cols = [x for x in df_final.columns if \"GEOM_R\" in x]\n",
    "geom_dist_cols = [x for x in df_final.columns if \"GEOM_DIST4\" in x]\n",
    "geom_prob_cols = [x for x in df_final.columns if \"GEOM_PROB\" in x]\n",
    "xy_dens_cols = [x for x in df_final.columns if \"XY_DENS\" in x]\n",
    "xy_ori_cols = ['X','Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clase_weights = np.array([6.26193840e-05, 4.64739874e-05, 4.55873618e-05, 3.83198034e-05, 3.78393795e-05, 4.81255214e-06, 4.26270960e-05])\n",
    "sample_weight = clase_weights[le.fit_transform(df.CLASE)].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(df_join[['X','Y']])\n",
    "xy_temp = ss.transform(df_join[['X','Y']])\n",
    "xy_temp = np.array([lmx.predict(xy_temp[:,:1]),lmy.predict(xy_temp[:,1:])]).T\n",
    "\n",
    "points = np.array([(2.207524e9, 165.5605e6), (2.207524e9, 165.5605e6), (2.170449e9, 166.0036e6),\n",
    "          (2.205824e9, 166.3199e6), (2.250042e9, 166.2673e6), (2.270527e9, 165.9025e6),\n",
    "          (2.274459e9, 165.5947e6), (2.269886e9, 165.3261e6), (2.211719e9, 165.1699e6),\n",
    "          (2.156419e9, 165.2959e6), (2.142472e9, 165.4747e6), (2.141374e9, 165.8068e6),\n",
    "          (2.166906e9, 165.7316e6), (2.187454e9, 165.4168e6), (2.174702e9, 165.481e6),\n",
    "          (2.202014e9, 165.5483e6), (2.215004e9, 165.4046e6), (2.196768e9, 165.4717e6),\n",
    "          (2.236186e9, 165.4013e6), (2.220204e9, 165.4714e6), (2.219742e9, 165.8038e6)])\n",
    "points = ss.transform(points)\n",
    "points = np.array([lmx.predict(points[:,:1]),lmy.predict(points[:,1:])]).T\n",
    "\n",
    "distances = np.array([np.linalg.norm(xy_temp - b, axis=1) for b in points])\n",
    "_= plt.boxplot(np.array(distances).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_cols = [f'C_DIST_{i}' for i in range(points.shape[0])]\n",
    "distances_df = pd.DataFrame(distances.T,columns=distances_cols,index=df_join.index)\n",
    "df_final = pd.concat([df_final,distances_df],axis=1)\n",
    "\n",
    "df_final[xy_dens_cols] = np.clip(df_final[xy_dens_cols],-np.inf,np.exp(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define N points P\n",
    "N = 7\n",
    "\n",
    "yl = le.transform(df.CLASE)\n",
    "yl_hist = (clase_weights*(np.unique(df.CLASE,return_counts=True)[1])**2)\n",
    "def get_hist(mini_yl):\n",
    "    mini_yl_hist = np.histogram(mini_yl,bins=le.classes_.size, range=(0,le.classes_.size), density=False)[0]\n",
    "    mini_yl_hist = mini_yl_hist/ yl_hist\n",
    "    mini_yl_hist = mini_yl_hist / mini_yl_hist.sum()\n",
    "    return mini_yl_hist\n",
    "\n",
    "xyt = df_xyt[['X','Y']].values[:df.shape[0]]\n",
    "    \n",
    "def eval_class_dist(p):    \n",
    "    p = p.reshape(2,-1).T\n",
    "\n",
    "    # for x in XY\n",
    "        # get closer P\n",
    "        # assign p\n",
    "\n",
    "    closer_p = np.argmin([np.power(xyt - p[i:i+1],2).sum(1) for i in range(N)],0)\n",
    "    # strain point\n",
    "    if np.unique(closer_p).size != N:\n",
    "        return 0\n",
    "    \n",
    "    # for p in P:\n",
    "        # get normalized distribution\n",
    "    p_hist = np.array([get_hist(yl[closer_p == i]) for i in range(N)])\n",
    "    p_size = np.array([np.clip(5*(closer_p==i).sum()/(yl.size/N),0,1) for i in range(N)])\n",
    "    #     print(p_hist)\n",
    "    # maximize distance matrix\n",
    "    # hist_dist = distance_matrix(p_hist,p_hist).sum()\n",
    "    hist_dist = distance_matrix(p_hist,p_hist)*(p_size[:,None]*p_size[None,:])\n",
    "    return -hist_dist.sum()\n",
    "\n",
    "# for i in range(10,100):\n",
    "#     np.random.seed(i)\n",
    "#     p = np.random.uniform(xyt.min(0),xyt.max(0),[N,2]).ravel()\n",
    "#     print(i,eval_class_dist(p))\n",
    "\n",
    "de_dist = differential_evolution(\n",
    "    eval_class_dist,\n",
    "    bounds=list(zip(*np.repeat((xyt.min(0),xyt.max(0)),N,axis=1))),\n",
    "    workers=-1,\n",
    "    maxiter=1000,\n",
    ")\n",
    "de_best_x = de_dist.x.reshape(2,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyt_all = df_xyt[['X','Y']].values\n",
    "dist_to_de_points = np.sqrt((((xyt_all[:,None,:]-de_best_x[None,:,:]))**2).sum(-1))\n",
    "dist_de_cols =[f'DE_DIST_{i}' for i in range(dist_to_de_points.shape[1])]\n",
    "dtdp_df = pd.DataFrame(dist_to_de_points,columns=dist_de_cols,index=df_join.index)\n",
    "df_final = pd.concat([df_join,dtdp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = de_best_x\n",
    "\n",
    "# for x in XY\n",
    "    # get closer P\n",
    "    # assign p\n",
    "yl = le.transform(df.CLASE)\n",
    "yl_hist = (clase_weights*(np.unique(df.CLASE,return_counts=True)[1])**2)\n",
    "def get_hist(mini_yl):\n",
    "    mini_yl_hist = np.histogram(mini_yl,bins=le.classes_.size, range=(0,le.classes_.size), density=False)[0]\n",
    "    mini_yl_hist = mini_yl_hist/ yl_hist\n",
    "    mini_yl_hist = mini_yl_hist / mini_yl_hist.sum()\n",
    "    return mini_yl_hist\n",
    "\n",
    "closer_p = np.argmin([np.power(xyt - p[i:i+1],2).sum(1) for i in range(N)],0)\n",
    "\n",
    "# for p in P:\n",
    "        # get normalized distribution\n",
    "p_hist = np.array([get_hist(yl[closer_p == i]) for i in range(N)])\n",
    "p_size = np.array([np.clip(5*(closer_p==i).sum()/(yl.size/N),0,1) for i in range(N)])\n",
    "#     print(p_hist)\n",
    "# maximize distance matrix\n",
    "# hist_dist = distance_matrix(p_hist,p_hist).sum()\n",
    "hist_dist = distance_matrix(p_hist,p_hist)*(p_size[:,None]*p_size[None,:])\n",
    "\n",
    "\n",
    "plt.imshow(hist_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = df_join[[x for x in df_join.columns if \"GEOM\" in x]].copy()\n",
    "geom.iloc[:,1:] = np.log(geom.iloc[:,1:])\n",
    "geom = ss.fit_transform(geom)\n",
    "for d in (geom.T):\n",
    "    sns.distplot(d)\n",
    "    \n",
    "nlist = 100\n",
    "k = 4\n",
    "agg = np.mean\n",
    "\n",
    "res = []\n",
    "\n",
    "db_matrix = geom\n",
    "\n",
    "xyt_all = df_xyt[['X','Y']].values\n",
    "p = de_best_x\n",
    "closer_p = np.argmin([np.power(xyt_all - p[i:i+1],2).sum(1) for i in range(N)],0)\n",
    "\n",
    "\n",
    "for c in le.classes_:\n",
    "    class_mask = df_join.CLASE == c\n",
    "    \n",
    "    mean_d = np.zeros((class_mask.size,k))\n",
    "    mean_d[:] = np.nan\n",
    "    mean_check = np.zeros((class_mask.size))\n",
    "    \n",
    "    for p_val in np.arange(closer_p.max()):\n",
    "        \n",
    "        class_p_mask = class_mask & (closer_p == p_val)\n",
    "        class_notp_mask = (~class_mask) & (closer_p == p_val)\n",
    "        \n",
    "#         print((closer_p == p_val).sum(),class_p_mask.sum(),class_notp_mask.sum())\n",
    "        \n",
    "        db = db_matrix[class_p_mask].astype(np.float32)\n",
    "        rest = db_matrix[class_notp_mask].astype(np.float32)\n",
    "                \n",
    "        if db.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "\n",
    "        # Train db           # add may be a bit slower as well\n",
    "        k_max = np.min([k+1,db.shape[0]])\n",
    "        nn = NearestNeighbors(k_max,n_jobs=-1,metric='manhattan')\n",
    "        nn.fit(db)\n",
    "\n",
    "        # Predict train\n",
    "        D,I = nn.kneighbors(db)\n",
    "        \n",
    "        if k_max > 1:\n",
    "            mean_d[class_p_mask,:k_max-1] = (D[:,1:k_max])\n",
    "            mean_check[class_p_mask] += 1\n",
    "\n",
    "        # Predict rest\n",
    "        D, I = nn.kneighbors(rest)\n",
    "        mean_d[class_notp_mask,:k_max] = (D[:,:np.min([k,k_max])])\n",
    "        mean_check[class_notp_mask] += 1\n",
    "\n",
    "    res.append(mean_d)\n",
    "    \n",
    "res = np.array(res)\n",
    "res[np.isnan(res)] = np.max(res[~np.isnan(res)])*2\n",
    "\n",
    "res = agg(res,axis=2).T\n",
    "res = np.log(res+1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    sns.distplot(res[:,i]+1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# GEOM DIST DATAFRAME\n",
    "#\n",
    "geom_dist_de_cols = [f'GEOM_DIST4_DE_{c}' for c in le.classes_]\n",
    "geom_dist_de = pd.DataFrame(res,index=df_join.index,columns=geom_dist_de_cols)\n",
    "df_final = pd.concat([df_final,geom_dist_de],axis=1)\n",
    "\n",
    "#\n",
    "# GEOM DIST SOFTMAX\n",
    "#\n",
    "# res_log = np.log(res+3e-2)\n",
    "res_log = res\n",
    "res_log -= res_log.min()\n",
    "res_log /= res_log.max()\n",
    "res_log = 1-res_log\n",
    "\n",
    "from scipy.special import softmax\n",
    "geom_nn4_prob_de_cols = [f'GEOM_PROB_DE_{c}' for c in le.classes_]\n",
    "geom_nn4_prob_de = pd.DataFrame(softmax(res_log,axis=1),index=df_join.index,columns=geom_nn4_prob_de_cols)\n",
    "df_final = pd.concat([df_final,geom_nn4_prob_de],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM_COLS\n",
    "df_final['VALUE'] = df_final['AREA'] * df_final['CADASTRALQUALITYID'] * df_final['MAXBUILDINGFLOOR']\n",
    "df_final['VALUE2'] = df_final['AREA'] * df_final['CADASTRALQUALITYID']\n",
    "df_final['VALUE3'] = df_final['CADASTRALQUALITYID'] * df_final['MAXBUILDINGFLOOR']\n",
    "df_final['VALUE4'] = df_final['AREA'] * df_final['MAXBUILDINGFLOOR']\n",
    "df_final['VALUE5'] = df_final['AREA'] / df_final['MAXBUILDINGFLOOR']+1\n",
    "\n",
    "custom_cols = ['VALUE', 'VALUE2', 'VALUE3', 'VALUE4', 'VALUE5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "rsearch = RandomizedSearchCV(param_distributions={\n",
    "    'learning_rate': np.linspace(1e-2,10,100), \n",
    "    min_child_weight= np.arange(1,10),\n",
    "    gamma=np.linspace(0,10,100),\n",
    "    subsample=np.linspace(0,1,100),\n",
    "    colsample_bytree=np.linspace(0,1,100),\n",
    "    max_depth=np.arange(1,50),\n",
    "    n_estimators=np.arange(100,1500,100)\n",
    "},n_iter=100)\n",
    "\n",
    "xgboost = XGBClassifier(n_jobs=-1)\n",
    "rsearch.fit(xgboost,x,y,fit_params={'sample_weight':sample_weight*y.size})\n",
    "\n",
    "xgboost = rsearch.best_estimator_\n",
    "\n",
    "mod_cols = basic_cols+geom_ori_cols+geom_dist_cols+rgbn_cols+xy_dens_cols+custom_cols+dist_de_cols+geom_dist_de_cols+geom_nn4_prob_de_cols\n",
    "\n",
    "x = df_final[mod_cols].iloc[:df.shape[0]]\n",
    "y = df.CLASE\n",
    "\n",
    "xgboost.fit(x,y,sample_weight=sample_weight*y.size)\n",
    "\n",
    "fig,ax = plt.subplots(1,figsize=(20,20))\n",
    "plot_importance(xgboost,ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ts = df_final[mod_cols].iloc[df.shape[0]:]\n",
    "yp_ts = xgboost.predict_proba(x_ts)\n",
    "\n",
    "pd.DataFrame({'CLASE':le.inverse_transform(yp_ts.argmax(1))},index=df_test.index).to_csv('../Universidad de Granada_Code Digger.txt',sep='|',encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
